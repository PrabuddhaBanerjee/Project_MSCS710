{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of cities.\n",
      "datetime|Vancouver|Portland|San Francisco|Seattle|Los Angeles|San Diego|Las Vegas|Phoenix|Albuquerque|Denver|San Antonio|Dallas|Houston|Kansas City|Minneapolis|Saint Louis|Chicago|Nashville|Indianapolis|Atlanta|Detroit|Jacksonville|Charlotte|Miami|Pittsburgh|Toronto|Philadelphia|New York|Montreal|Boston|Beersheba|Tel Aviv District|Eilat|Haifa|Nahariyya|Jerusalem\n",
      "Loaded all csvs.\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Output to csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# weather data Oct 2012 -> Nov 2017\n",
    "humidity      = pd.read_csv('../weather_data/humidity.csv')\n",
    "pressure      = pd.read_csv('../weather_data/pressure.csv')\n",
    "temperature   = pd.read_csv('../weather_data/temperature.csv')\n",
    "wind_dir      = pd.read_csv('../weather_data/wind_direction.csv')\n",
    "wind_speed    = pd.read_csv('../weather_data/wind_speed.csv')\n",
    "weather_desc  = pd.read_csv('../weather_data/weather_description.csv')\n",
    "\n",
    "# list of cities to search weather data for. Can grab from any weather header\n",
    "cities = humidity.columns.to_list()\n",
    "print(\"List of cities.\")\n",
    "#use regex to create a search pattern\n",
    "cities_ptrn = '|'.join(cities)\n",
    "print(cities_ptrn)\n",
    "\n",
    "# airline data Oct 2012 -> Nov 2017 \n",
    "oct_2012 = pd.read_csv('../airline_data/Oct2012.csv')\n",
    "nov_2012 = pd.read_csv('../airline_data/Nov2012.csv')\n",
    "dec_2012 = pd.read_csv('../airline_data/Dec2012.csv')\n",
    "jan_2013 = pd.read_csv('../airline_data/Jan2013.csv')\n",
    "feb_2013 = pd.read_csv('../airline_data/Feb2013.csv')\n",
    "mar_2013 = pd.read_csv('../airline_data/Mar2013.csv')\n",
    "apr_2013 = pd.read_csv('../airline_data/Apr2013.csv')\n",
    "may_2013 = pd.read_csv('../airline_data/May2013.csv')\n",
    "jun_2013 = pd.read_csv('../airline_data/Jun2013.csv')\n",
    "jul_2013 = pd.read_csv('../airline_data/Jul2013.csv')\n",
    "aug_2013 = pd.read_csv('../airline_data/Aug2013.csv')\n",
    "sep_2013 = pd.read_csv('../airline_data/Sep2013.csv')\n",
    "oct_2013 = pd.read_csv('../airline_data/Oct2013.csv')\n",
    "nov_2013 = pd.read_csv('../airline_data/Nov2013.csv')\n",
    "dec_2013 = pd.read_csv('../airline_data/Dec2013.csv')\n",
    "jan_2014 = pd.read_csv('../airline_data/Jan2014.csv')\n",
    "feb_2014 = pd.read_csv('../airline_data/Feb2014.csv')\n",
    "mar_2014 = pd.read_csv('../airline_data/Mar2014.csv')\n",
    "apr_2014 = pd.read_csv('../airline_data/Apr2014.csv')\n",
    "may_2014 = pd.read_csv('../airline_data/May2014.csv')\n",
    "jun_2014 = pd.read_csv('../airline_data/Jun2014.csv')\n",
    "jul_2014 = pd.read_csv('../airline_data/Jul2014.csv')\n",
    "aug_2014 = pd.read_csv('../airline_data/Aug2014.csv')\n",
    "sep_2014 = pd.read_csv('../airline_data/Sep2014.csv')\n",
    "oct_2014 = pd.read_csv('../airline_data/Oct2015.csv')\n",
    "nov_2014 = pd.read_csv('../airline_data/Nov2015.csv')\n",
    "dec_2014 = pd.read_csv('../airline_data/Dec2015.csv')\n",
    "jan_2015 = pd.read_csv('../airline_data/Jan2015.csv')\n",
    "feb_2015 = pd.read_csv('../airline_data/Feb2015.csv')\n",
    "mar_2015 = pd.read_csv('../airline_data/Mar2015.csv')\n",
    "apr_2015 = pd.read_csv('../airline_data/Apr2015.csv')\n",
    "may_2015 = pd.read_csv('../airline_data/May2015.csv')\n",
    "jun_2015 = pd.read_csv('../airline_data/Jun2015.csv')\n",
    "jul_2015 = pd.read_csv('../airline_data/Jul2015.csv')\n",
    "aug_2015 = pd.read_csv('../airline_data/Aug2015.csv')\n",
    "sep_2015 = pd.read_csv('../airline_data/Sep2015.csv')\n",
    "oct_2015 = pd.read_csv('../airline_data/Oct2015.csv')\n",
    "nov_2015 = pd.read_csv('../airline_data/Nov2015.csv')\n",
    "dec_2015 = pd.read_csv('../airline_data/Dec2015.csv')\n",
    "jan_2016 = pd.read_csv('../airline_data/Jan2016.csv')\n",
    "feb_2016 = pd.read_csv('../airline_data/Feb2016.csv')\n",
    "mar_2016 = pd.read_csv('../airline_data/Mar2016.csv')\n",
    "apr_2016 = pd.read_csv('../airline_data/Apr2016.csv')\n",
    "may_2016 = pd.read_csv('../airline_data/May2016.csv')\n",
    "jun_2016 = pd.read_csv('../airline_data/Jun2016.csv')\n",
    "jul_2016 = pd.read_csv('../airline_data/Jul2016.csv')\n",
    "aug_2016 = pd.read_csv('../airline_data/Aug2016.csv')\n",
    "sep_2016 = pd.read_csv('../airline_data/Sep2016.csv')\n",
    "oct_2016 = pd.read_csv('../airline_data/Oct2016.csv')\n",
    "nov_2016 = pd.read_csv('../airline_data/Nov2016.csv')\n",
    "dec_2016 = pd.read_csv('../airline_data/Dec2016.csv')\n",
    "jan_2017 = pd.read_csv('../airline_data/Jan2017.csv')\n",
    "feb_2017 = pd.read_csv('../airline_data/Feb2017.csv')\n",
    "mar_2017 = pd.read_csv('../airline_data/Mar2017.csv')\n",
    "apr_2017 = pd.read_csv('../airline_data/Apr2017.csv')\n",
    "may_2017 = pd.read_csv('../airline_data/May2017.csv')\n",
    "jun_2017 = pd.read_csv('../airline_data/Jun2017.csv')\n",
    "jul_2017 = pd.read_csv('../airline_data/Jul2017.csv')\n",
    "aug_2017 = pd.read_csv('../airline_data/Aug2017.csv')\n",
    "sep_2017 = pd.read_csv('../airline_data/Sep2017.csv')\n",
    "oct_2017 = pd.read_csv('../airline_data/Oct2017.csv')\n",
    "nov_2017 = pd.read_csv('../airline_data/Nov2017.csv')\n",
    "print(\"Loaded all csvs.\")\n",
    "\n",
    "# For the first step of trimming remove all flights that don't have weather data that corresponds\n",
    "# to the origin or destination airport (filter on city names)\n",
    "# For size constraints do this one dataframe at a time\n",
    "init_dfs = [oct_2012, nov_2012, dec_2012, \n",
    "               jan_2013, feb_2013, mar_2013, apr_2013, may_2013, jun_2013, \n",
    "               jul_2013, aug_2013, sep_2013, oct_2013, nov_2013, dec_2013, \n",
    "               jan_2014, feb_2014, mar_2014, apr_2014, may_2014, jun_2014, \n",
    "               jul_2014, aug_2014, sep_2014, oct_2014, nov_2014, dec_2014, \n",
    "               jan_2015, feb_2015, mar_2015, apr_2015, may_2015, jun_2015, \n",
    "               jul_2015, aug_2015, sep_2015, oct_2015, nov_2015, dec_2015, \n",
    "               jan_2016, feb_2016, mar_2016, apr_2016, may_2016, jun_2016, \n",
    "               jul_2016, aug_2016, sep_2016, oct_2016, nov_2016, dec_2016, \n",
    "               jan_2017, feb_2017, mar_2017, apr_2017, may_2017, jun_2017, \n",
    "               jul_2017, aug_2017, sep_2017, oct_2017, nov_2017 ] \n",
    "              \n",
    "# pull out data only for cities in the list\n",
    "airline_dfs =[]\n",
    "for df in init_dfs:\n",
    "    df = df.loc[df['ORIGIN_CITY_NAME'].str.contains(cities_ptrn, na=False) \n",
    "                & df['DEST_CITY_NAME'].str.contains(cities_ptrn, na=False)]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    airline_dfs.append(df)\n",
    "    \n",
    "print(\"Completed city screens.\")\n",
    "\n",
    "# create a base dataframe to work with\n",
    "airline_df = pd.concat(airline_dfs)\n",
    "airline_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#drop random unnamed column\n",
    "airline_df.drop(columns=['Unnamed: 20'], inplace=True) \n",
    "print(\"Completed concat and reindex\")\n",
    "\n",
    "airline_df.to_csv(\"../airline_data/Oct2012_Nov2017.csv\",index=False)\n",
    "print(\"Output to csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of cities.\n",
      "datetime|Vancouver|Portland|San Francisco|Seattle|Los Angeles|San Diego|Las Vegas|Phoenix|Albuquerque|Denver|San Antonio|Dallas|Houston|Kansas City|Minneapolis|Saint Louis|Chicago|Nashville|Indianapolis|Atlanta|Detroit|Jacksonville|Charlotte|Miami|Pittsburgh|Toronto|Philadelphia|New York|Montreal|Boston|Beersheba|Tel Aviv District|Eilat|Haifa|Nahariyya|Jerusalem\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "62218229\n",
      "Memory after refactor\n",
      "43015226\n",
      "Output to csv../airline_data/Nov2012_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "63700125\n",
      "Memory after refactor\n",
      "44039171\n",
      "Output to csv../airline_data/Nov2013_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "60601849\n",
      "Memory after refactor\n",
      "41903579\n",
      "Output to csv../airline_data/Nov2014_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "63031103\n",
      "Memory after refactor\n",
      "43573927\n",
      "Output to csv../airline_data/Nov2015_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "62522913\n",
      "Memory after refactor\n",
      "43233670\n",
      "Output to csv../airline_data/Nov2017_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "62518423\n",
      "Memory after refactor\n",
      "43234159\n",
      "Output to csv../airline_data/Nov2016_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "64114413\n",
      "Memory after refactor\n",
      "44324678\n",
      "Output to csv../airline_data/Apr2015_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "63965467\n",
      "Memory after refactor\n",
      "44198639\n",
      "Output to csv../airline_data/Dec2015_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "62131257\n",
      "Memory after refactor\n",
      "42954147\n",
      "Output to csv../airline_data/Dec2014_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "65805596\n",
      "Memory after refactor\n",
      "45500547\n",
      "Output to csv../airline_data/Sep2013_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "62906770\n",
      "Memory after refactor\n",
      "43498751\n",
      "Output to csv../airline_data/Apr2014_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "66291255\n",
      "Memory after refactor\n",
      "45785835\n",
      "Output to csv../airline_data/Oct2012_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "63714863\n",
      "Memory after refactor\n",
      "44042588\n",
      "Output to csv../airline_data/Apr2016_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "62819822\n",
      "Memory after refactor\n",
      "43409199\n",
      "Output to csv../airline_data/Dec2016_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "63544126\n",
      "Memory after refactor\n",
      "43905100\n",
      "Output to csv../airline_data/Apr2017_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "68845171\n",
      "Memory after refactor\n",
      "47610232\n",
      "Output to csv../airline_data/Oct2013_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "67665625\n",
      "Memory after refactor\n",
      "46782969\n",
      "Output to csv../airline_data/Oct2017_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "62753041\n",
      "Memory after refactor\n",
      "43381232\n",
      "Output to csv../airline_data/Sep2014_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "65932317\n",
      "Memory after refactor\n",
      "45566340\n",
      "Output to csv../airline_data/Apr2013_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "65261378\n",
      "Memory after refactor\n",
      "45082887\n",
      "Output to csv../airline_data/Dec2013_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "62630471\n",
      "Memory after refactor\n",
      "43295266\n",
      "Output to csv../airline_data/Dec2012_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "64534657\n",
      "Memory after refactor\n",
      "44627758\n",
      "Output to csv../airline_data/Sep2015_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "67115071\n",
      "Memory after refactor\n",
      "46401216\n",
      "Output to csv../airline_data/Oct2016_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "65795157\n",
      "Memory after refactor\n",
      "45490851\n",
      "Output to csv../airline_data/Oct2014_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "64719689\n",
      "Memory after refactor\n",
      "44694285\n",
      "Output to csv../airline_data/Sep2017_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "64918331\n",
      "Memory after refactor\n",
      "44891425\n",
      "Output to csv../airline_data/Sep2016_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "67182098\n",
      "Memory after refactor\n",
      "46457896\n",
      "Output to csv../airline_data/Oct2015_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "60661594\n",
      "Memory after refactor\n",
      "41901826\n",
      "Output to csv../airline_data/Jan2016_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "70861707\n",
      "Memory after refactor\n",
      "48970828\n",
      "Output to csv../airline_data/Aug2016_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "67763725\n",
      "Memory after refactor\n",
      "46838904\n",
      "Output to csv../airline_data/May2017_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "67634645\n",
      "Memory after refactor\n",
      "46763396\n",
      "Output to csv../airline_data/May2016_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "71355355\n",
      "Memory after refactor\n",
      "49273168\n",
      "Output to csv../airline_data/Aug2017_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "61051410\n",
      "Memory after refactor\n",
      "42181344\n",
      "Output to csv../airline_data/Jan2017_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "61171116\n",
      "Memory after refactor\n",
      "42252144\n",
      "Output to csv../airline_data/Jan2015_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "70184690\n",
      "Memory after refactor\n",
      "48522473\n",
      "Output to csv../airline_data/Aug2015_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "65997051\n",
      "Memory after refactor\n",
      "45616233\n",
      "Output to csv../airline_data/May2014_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "67336845\n",
      "Memory after refactor\n",
      "46545543\n",
      "Output to csv../airline_data/May2015_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "66760641\n",
      "Memory after refactor\n",
      "46159905\n",
      "Output to csv../airline_data/Aug2014_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "69456567\n",
      "Memory after refactor\n",
      "48000736\n",
      "Output to csv../airline_data/Jun2013_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "61469941\n",
      "Memory after refactor\n",
      "42377355\n",
      "Output to csv../airline_data/Jan2014_fix.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "68646277\n",
      "Memory after refactor\n",
      "47442177\n",
      "Output to csv../airline_data/Jun2017_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "68682573\n",
      "Memory after refactor\n",
      "47474181\n",
      "Output to csv../airline_data/Jun2016_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "62889073\n",
      "Memory after refactor\n",
      "43479298\n",
      "Output to csv../airline_data/Jan2013_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "65833415\n",
      "Memory after refactor\n",
      "45505845\n",
      "Output to csv../airline_data/Jun2014_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "71257374\n",
      "Memory after refactor\n",
      "49269213\n",
      "Output to csv../airline_data/Aug2013_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "68426648\n",
      "Memory after refactor\n",
      "47284946\n",
      "Output to csv../airline_data/Jun2015_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "68600864\n",
      "Memory after refactor\n",
      "47431474\n",
      "Output to csv../airline_data/May2013_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "70621843\n",
      "Memory after refactor\n",
      "48808752\n",
      "Output to csv../airline_data/Jul2017_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "67295963\n",
      "Memory after refactor\n",
      "46516193\n",
      "Output to csv../airline_data/Mar2013_fix.csv\n",
      "Completed city screens.\n",
      "Completed concat and reindex\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "70748052\n",
      "Memory after refactor\n",
      "48882186\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# weather data Oct 2012 -> Nov 2017\n",
    "humidity = pd.read_csv('../weather_data/humidity.csv')\n",
    "\n",
    "# list of cities to search weather data for. Can grab from any weather header\n",
    "cities = humidity.columns.to_list()\n",
    "print(\"List of cities.\")\n",
    "#use regex to create a search pattern\n",
    "cities_ptrn = '|'.join(cities)\n",
    "print(cities_ptrn)\n",
    "\n",
    "# Get all flight files\n",
    "flight_path = r'../airline_data'\n",
    "flight_filenames = glob.glob(flight_path + \"/*.csv\")\n",
    "\n",
    "# Loop through flight files and add data to database\n",
    "for filename in flight_filenames:\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.loc[df['ORIGIN_CITY_NAME'].str.contains(cities_ptrn, na=False) \n",
    "                & df['DEST_CITY_NAME'].str.contains(cities_ptrn, na=False)]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    print(\"Completed city screens.\")\n",
    "\n",
    "    #drop random unnamed column\n",
    "    df.drop(columns=['Unnamed: 20'], inplace=True) \n",
    "    print(\"Completed concat and reindex\")\n",
    "    \n",
    "\n",
    "    # Add an HOUR field to the flight data to help merges\n",
    "    df.loc[:,'HOUR'] = [i for i in df.CRS_DEP_TIME.floordiv(100)]\n",
    "    df.drop(columns=['CRS_DEP_TIME'], inplace=True) # we no longer need this\n",
    "    print('Drop CRS_DEP_TIME in favor of HOUR')\n",
    "\n",
    "\n",
    "    #Compress the memory size of the df\n",
    "    print(\"Memory before refactor\")\n",
    "    print(df.memory_usage(deep=True).sum())\n",
    "    df[['CANCELLATION_CODE']] = df[['CANCELLATION_CODE']].fillna(\"E\")\n",
    "    df.fillna(0, inplace=True)\n",
    "    df.loc[:,'YEAR'] = df['YEAR'].astype(np.int16)\n",
    "    df.loc[:,'MONTH'] = df['MONTH'].astype(np.int8)\n",
    "    df.loc[:,'DAY_OF_MONTH'] = df['DAY_OF_MONTH'].astype(np.int8)\n",
    "    df.loc[:,'DAY_OF_WEEK'] = df['DAY_OF_WEEK'].astype(np.int8)\n",
    "    df.loc[:,'OP_CARRIER_AIRLINE_ID'] = df['OP_CARRIER_AIRLINE_ID'].astype(np.int16)\n",
    "    df.loc[:,'HOUR'] = df['HOUR'].astype(np.int8)\n",
    "    df.loc[:,'DEP_DELAY'] = df['DEP_DELAY'].astype(np.int16)\n",
    "    df.loc[:,'DEP_DELAY_NEW'] = df['DEP_DELAY_NEW'].astype(np.int16)\n",
    "    df.loc[:,'DEP_DELAY_GROUP'] = df['DEP_DELAY_GROUP'].astype(np.int8)\n",
    "    df.loc[:,'CANCELLED'] = df['CANCELLED'].astype(np.int8)\n",
    "    df.loc[:,'CARRIER_DELAY'] = df['CARRIER_DELAY'].astype(np.int16)\n",
    "    df.loc[:,'WEATHER_DELAY'] = df['WEATHER_DELAY'].astype(np.int16)\n",
    "    df.loc[:,'NAS_DELAY'] = df['NAS_DELAY'].astype(np.int16)\n",
    "    df.loc[:,'SECURITY_DELAY'] = df['SECURITY_DELAY'].astype(np.int16)\n",
    "    df.loc[:,'LATE_AIRCRAFT_DELAY'] = df['LATE_AIRCRAFT_DELAY'].astype(np.int16)\n",
    "    df.loc[:,'CARRIER_DELAY'] = df['CARRIER_DELAY'].astype(np.int16)\n",
    "\n",
    "    #fix cancellation code\n",
    "    df.loc[:,'CANCELLATION_CODE'] = [ord(c)-65 for c in df['CANCELLATION_CODE']]\n",
    "    df.loc[:,'CANCELLATION_CODE'] = df['CANCELLATION_CODE'].astype(np.int8)\n",
    "\n",
    "    print(\"Memory after refactor\")\n",
    "    print(df.memory_usage(deep=True).sum())\n",
    "\n",
    "    df.to_csv(filename[:-4] + \"_fix.csv\",index=False)\n",
    "    print(\"Output to csv\" + filename[:-4] + \"_fix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished:  datetime\n",
      "Finished:  Vancouver\n",
      "Finished:  Portland\n",
      "Finished:  San Francisco\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fb6f73762a97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Change column values for origin and dest city to match weather data list for ease of matching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mairline_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mairline_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ORIGIN_CITY_NAME\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ORIGIN_CITY_NAME\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mairline_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mairline_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DEST_CITY_NAME\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DEST_CITY_NAME\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MSCS710/MSCS710_Team_Air_Services/air_env/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1999\u001b[0m                 )\n\u001b[1;32m   2000\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MSCS710/MSCS710_Team_Air_Services/air_env/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mcontains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m   2823\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2824\u001b[0m         result = str_contains(\n\u001b[0;32m-> 2825\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2826\u001b[0m         )\n\u001b[1;32m   2827\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MSCS710/MSCS710_Team_Air_Services/air_env/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mstr_contains\u001b[0;34m(arr, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0muppered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muppered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MSCS710/MSCS710_Team_Air_Services/air_env/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_na_map\u001b[0;34m(f, arr, na_result, dtype)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mna_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_map_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MSCS710/MSCS710_Team_Air_Services/air_env/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_map_object\u001b[0;34m(f, arr, na_mask, na_value, dtype)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;31m# Reraise the exception if callable `f` got wrong number of args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MSCS710/MSCS710_Team_Air_Services/air_env/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    447\u001b[0m             )\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "airline_df = pd.read_csv('../airline_data/Oct2012_Nov2017.csv')\n",
    "\n",
    "# Curate the data\n",
    "# Change column values for origin and dest city to match weather data list for ease of matching\n",
    "for city in cities:\n",
    "    airline_df.loc[airline_df[\"ORIGIN_CITY_NAME\"].str.contains(city), \"ORIGIN_CITY_NAME\"] = city\n",
    "    airline_df.loc[airline_df[\"DEST_CITY_NAME\"].str.contains(city), \"DEST_CITY_NAME\"] = city\n",
    "    print(\"Finished: \", city)\n",
    "print(\"Completed city renames.\")\n",
    "    \n",
    "airline_df.to_csv(\"../airline_data/airlines_city_fix.csv\",index=False)\n",
    "print(\"Output to csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Drop CRS_DEP_TIME in favor of HOUR\n",
      "Memory before refactor\n",
      "3949983764\n",
      "Memory after refactor\n",
      "2701904404\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(\"Starting\")\n",
    "\n",
    "airline_df = pd.read_csv('../airline_data/airlines_city_fix.csv')\n",
    "\n",
    "# Add an HOUR field to the flight data to help merges\n",
    "airline_df.loc[:,'HOUR'] = [i for i in airline_df.CRS_DEP_TIME.floordiv(100)]\n",
    "airline_df.drop(columns=['CRS_DEP_TIME'], inplace=True) # we no longer need this\n",
    "print('Drop CRS_DEP_TIME in favor of HOUR')\n",
    "\n",
    "\n",
    "#Compress the memory size of the df\n",
    "print(\"Memory before refactor\")\n",
    "print(airline_df.memory_usage(deep=True).sum())\n",
    "airline_df[['CANCELLATION_CODE']] = airline_df[['CANCELLATION_CODE']].fillna(\"E\")\n",
    "airline_df.fillna(0, inplace=True)\n",
    "airline_df.loc[:,'YEAR'] = airline_df['YEAR'].astype(np.int16)\n",
    "airline_df.loc[:,'MONTH'] = airline_df['MONTH'].astype(np.int8)\n",
    "airline_df.loc[:,'DAY_OF_MONTH'] = airline_df['DAY_OF_MONTH'].astype(np.int8)\n",
    "airline_df.loc[:,'DAY_OF_WEEK'] = airline_df['DAY_OF_WEEK'].astype(np.int8)\n",
    "airline_df.loc[:,'OP_CARRIER_AIRLINE_ID'] = airline_df['OP_CARRIER_AIRLINE_ID'].astype(np.int16)\n",
    "airline_df.loc[:,'HOUR'] = airline_df['HOUR'].astype(np.int8)\n",
    "airline_df.loc[:,'DEP_DELAY'] = airline_df['DEP_DELAY'].astype(np.int16)\n",
    "airline_df.loc[:,'DEP_DELAY_NEW'] = airline_df['DEP_DELAY_NEW'].astype(np.int16)\n",
    "airline_df.loc[:,'DEP_DELAY_GROUP'] = airline_df['DEP_DELAY_GROUP'].astype(np.int8)\n",
    "airline_df.loc[:,'CANCELLED'] = airline_df['CANCELLED'].astype(np.int8)\n",
    "airline_df.loc[:,'CARRIER_DELAY'] = airline_df['CARRIER_DELAY'].astype(np.int16)\n",
    "airline_df.loc[:,'WEATHER_DELAY'] = airline_df['WEATHER_DELAY'].astype(np.int16)\n",
    "airline_df.loc[:,'NAS_DELAY'] = airline_df['NAS_DELAY'].astype(np.int16)\n",
    "airline_df.loc[:,'SECURITY_DELAY'] = airline_df['SECURITY_DELAY'].astype(np.int16)\n",
    "airline_df.loc[:,'LATE_AIRCRAFT_DELAY'] = airline_df['LATE_AIRCRAFT_DELAY'].astype(np.int16)\n",
    "airline_df.loc[:,'CARRIER_DELAY'] = airline_df['CARRIER_DELAY'].astype(np.int16)\n",
    "\n",
    "#fix cancellation code\n",
    "airline_df.loc[:,'CANCELLATION_CODE'] = [ord(c)-65 for c in airline_df['CANCELLATION_CODE']]\n",
    "airline_df.loc[:,'CANCELLATION_CODE'] = airline_df['CANCELLATION_CODE'].astype(np.int8)\n",
    "\n",
    "print(\"Memory after refactor\")\n",
    "print(airline_df.memory_usage(deep=True).sum())\n",
    "\n",
    "airline_df.to_csv(\"../airline_data/airlines_final.csv\",index=False)\n",
    "print(\"Output to csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9130000\n",
      "Current memory usage\n",
      "5511634314\n",
      "0 , smoke\n",
      "1 , scattered clouds\n",
      "2 , sand/dust whirls\n",
      "3 , heavy thunderstorm\n",
      "4 , sand\n",
      "5 , thunderstorm\n",
      "6 , sleet\n",
      "7 , heavy snow\n",
      "8 , snow\n",
      "9 , thunderstorm with heavy drizzle\n",
      "10 , thunderstorm with drizzle\n",
      "11 , heavy intensity shower rain\n",
      "12 , light intensity shower rain\n",
      "13 , sky is clear\n",
      "14 , 0\n",
      "15 , light intensity drizzle rain\n",
      "16 , light rain and snow\n",
      "17 , overcast clouds\n",
      "18 , heavy intensity drizzle\n",
      "19 , thunderstorm with rain\n",
      "20 , mist\n",
      "21 , thunderstorm with light rain\n",
      "22 , shower rain\n",
      "23 , proximity shower rain\n",
      "24 , heavy intensity rain\n",
      "25 , proximity thunderstorm with rain\n",
      "26 , volcanic ash\n",
      "27 , proximity sand/dust whirls\n",
      "28 , very heavy rain\n",
      "29 , tornado\n",
      "30 , drizzle\n",
      "31 , freezing rain\n",
      "32 , few clouds\n",
      "33 , light snow\n",
      "34 , light intensity drizzle\n",
      "35 , proximity moderate rain\n",
      "36 , shower snow\n",
      "37 , fog\n",
      "38 , light shower sleet\n",
      "39 , squalls\n",
      "40 , light shower snow\n",
      "41 , heavy shower snow\n",
      "42 , thunderstorm with heavy rain\n",
      "43 , haze\n",
      "44 , ragged thunderstorm\n",
      "45 , dust\n",
      "46 , proximity thunderstorm with drizzle\n",
      "47 , proximity thunderstorm\n",
      "48 , shower drizzle\n",
      "49 , broken clouds\n",
      "50 , moderate rain\n",
      "51 , light rain\n",
      "52 , thunderstorm with light drizzle\n",
      "        YEAR  MONTH  DAY_OF_MONTH  DAY_OF_WEEK  OP_CARRIER_AIRLINE_ID ORIGIN  \\\n",
      "0       2012     10             2            2                  19805    JFK   \n",
      "1       2012     10             2            2                  19805    LAX   \n",
      "2       2012     10             2            2                  19805    LGA   \n",
      "3       2012     10             2            2                  19805    LGA   \n",
      "4       2012     10             2            2                  19805    ORD   \n",
      "...      ...    ...           ...          ...                    ...    ...   \n",
      "189995  2017     10             3            2                  19805    LGA   \n",
      "189996  2017     10             3            2                  19805    PHL   \n",
      "189997  2017     10             3            2                  19805    DEN   \n",
      "189998  2017     10             3            2                  19805    DFW   \n",
      "189999  2017     10             3            2                  19805    DFW   \n",
      "\n",
      "       ORIGIN_CITY_NAME DEST DEST_CITY_NAME  DEP_DELAY  ...  DEST_PRESSURE  \\\n",
      "0              New York  LAX    Los Angeles          6  ...           1013   \n",
      "1           Los Angeles  JFK       New York         68  ...           1012   \n",
      "2              New York  ORD        Chicago         -5  ...           1014   \n",
      "3              New York  ORD        Chicago         -7  ...           1014   \n",
      "4               Chicago  MSP    Minneapolis          2  ...           1012   \n",
      "...                 ...  ...            ...        ...  ...            ...   \n",
      "189995         New York  MIA          Miami         -6  ...           1015   \n",
      "189996     Philadelphia  ORD        Chicago         -4  ...           1024   \n",
      "189997           Denver  ORD        Chicago         -4  ...           1024   \n",
      "189998           Dallas  SEA        Seattle         -1  ...           1025   \n",
      "189999           Dallas  IAH        Houston         -3  ...           1016   \n",
      "\n",
      "        ORIGIN_PRESSURE  DEST_TEMPERATURE  ORIGIN_TEMPERATURE  DEST_WIND_DIR  \\\n",
      "0                  1012               291                 289              0   \n",
      "1                  1013               289                 291            267   \n",
      "2                  1012               286                 289              0   \n",
      "3                  1012               286                 289              0   \n",
      "4                  1014               287                 286            322   \n",
      "...                 ...               ...                 ...            ...   \n",
      "189995             1037               300                 284             70   \n",
      "189996             1036               292                 282            180   \n",
      "189997             1022               292                 275            180   \n",
      "189998             1018               279                 296             76   \n",
      "189999             1018               298                 296             20   \n",
      "\n",
      "        ORIGIN_WIND_DIR  DEST_WIND_SPEED  ORIGIN_WIND_SPEED  \\\n",
      "0                    11                0                  6   \n",
      "1                     0                6                  0   \n",
      "2                    11                0                  6   \n",
      "3                    11                0                  6   \n",
      "4                     0                4                  0   \n",
      "...                 ...              ...                ...   \n",
      "189995                0                3                  2   \n",
      "189996               40                5                  2   \n",
      "189997               92                5                  0   \n",
      "189998             -126                1                  3   \n",
      "189999             -126                3                  3   \n",
      "\n",
      "                   DEST_WEATHER   ORIGIN_WEATHER  \n",
      "0                  sky is clear       few clouds  \n",
      "1                    few clouds     sky is clear  \n",
      "2               overcast clouds       few clouds  \n",
      "3               overcast clouds       few clouds  \n",
      "4              scattered clouds  overcast clouds  \n",
      "...                         ...              ...  \n",
      "189995  light intensity drizzle     sky is clear  \n",
      "189996         scattered clouds             mist  \n",
      "189997         scattered clouds             mist  \n",
      "189998                     mist             mist  \n",
      "189999                     mist             mist  \n",
      "\n",
      "[9130000 rows x 32 columns]\n",
      "Final memory usage\n",
      "5511634314\n",
      "Output to csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "airline_df = pd.read_csv('../airline_data/airlines_city_fix.csv')\n",
    "\n",
    "# weather data Oct 2012 -> Nov 2017\n",
    "humidity      = pd.read_csv('../weather_data/humidity.csv')\n",
    "pressure      = pd.read_csv('../weather_data/pressure.csv')\n",
    "temperature   = pd.read_csv('../weather_data/temperature.csv')\n",
    "wind_dir      = pd.read_csv('../weather_data/wind_direction.csv')\n",
    "wind_speed    = pd.read_csv('../weather_data/wind_speed.csv')\n",
    "weather_desc  = pd.read_csv('../weather_data/weather_desc.csv')\n",
    "print(\"Loaded data\")\n",
    "\n",
    "# Add an HOUR field to the flight data to help merges\n",
    "airline_df.loc[:,'HOUR'] = [i for i in airline_df.CRS_DEP_TIME.floordiv(100)]\n",
    "airline_df.drop(columns=['CRS_DEP_TIME'], inplace=True) # we no longer need this\n",
    "print('Drop CRS_DEP_TIME in favor of HOUR')\n",
    "\n",
    "#Compress the memory size of the df\n",
    "print(\"Memory before refactor\")\n",
    "print(airline_df.memory_usage(deep=True).sum())\n",
    "airline_df[['CANCELLATION_CODE']] = airline_df[['CANCELLATION_CODE']].fillna(\"E\")\n",
    "airline_df.fillna(0, inplace=True)\n",
    "airline_df.loc[:,'YEAR'] = airline_df['YEAR'].astype(np.int16)\n",
    "airline_df.loc[:,'MONTH'] = airline_df['MONTH'].astype(np.int8)\n",
    "airline_df.loc[:,'DAY_OF_MONTH'] = airline_df['DAY_OF_MONTH'].astype(np.int8)\n",
    "airline_df.loc[:,'DAY_OF_WEEK'] = airline_df['DAY_OF_WEEK'].astype(np.int8)\n",
    "airline_df.loc[:,'OP_CARRIER_AIRLINE_ID'] = airline_df['OP_CARRIER_AIRLINE_ID'].astype(np.int16)\n",
    "airline_df.loc[:,'HOUR'] = airline_df['HOUR'].astype(np.int8)\n",
    "airline_df.loc[:,'DEP_DELAY'] = airline_df['DEP_DELAY'].astype(np.int16)\n",
    "airline_df.loc[:,'DEP_DELAY_NEW'] = airline_df['DEP_DELAY_NEW'].astype(np.int16)\n",
    "airline_df.loc[:,'DEP_DELAY_GROUP'] = airline_df['DEP_DELAY_GROUP'].astype(np.int8)\n",
    "airline_df.loc[:,'CANCELLED'] = airline_df['CANCELLED'].astype(np.int8)\n",
    "airline_df.loc[:,'CARRIER_DELAY'] = airline_df['CARRIER_DELAY'].astype(np.int16)\n",
    "airline_df.loc[:,'WEATHER_DELAY'] = airline_df['WEATHER_DELAY'].astype(np.int16)\n",
    "airline_df.loc[:,'NAS_DELAY'] = airline_df['NAS_DELAY'].astype(np.int16)\n",
    "airline_df.loc[:,'SECURITY_DELAY'] = airline_df['SECURITY_DELAY'].astype(np.int16)\n",
    "airline_df.loc[:,'LATE_AIRCRAFT_DELAY'] = airline_df['LATE_AIRCRAFT_DELAY'].astype(np.int16)\n",
    "airline_df.loc[:,'CARRIER_DELAY'] = airline_df['CARRIER_DELAY'].astype(np.int16)\n",
    "\n",
    "#fix cancellation code\n",
    "airline_df.loc[:,'CANCELLATION_CODE'] = [ord(c)-65 for c in airline_df['CANCELLATION_CODE']]\n",
    "airline_df.loc[:,'CANCELLATION_CODE'] = airline_df['CANCELLATION_CODE'].astype(np.int8)\n",
    "\n",
    "print(\"Memory after refactor\")\n",
    "print(airline_df.memory_usage(deep=True).sum())\n",
    "\n",
    " \n",
    "# Join the weather data with the flight data by creating origin/dest weather column for each attribute\n",
    "def join_weather_data(line, weather, name):\n",
    "    # Start by joining weather with air\n",
    "    weath = weather.copy()\n",
    "    weath.loc[:,'YEAR'] = weath.datetime.str[0:4]\n",
    "    weath.loc[:,'YEAR'] = weath['YEAR'].astype(int)\n",
    "    weath.loc[:,'MONTH'] = [s.lstrip(\"0\") for s in weath.datetime.str[5:7]]\n",
    "    weath.loc[:,'MONTH'] = weath['MONTH'].astype(int)\n",
    "    weath.loc[:,'DAY_OF_MONTH'] = [s.lstrip(\"0\") for s in weath.datetime.str[8:10]]\n",
    "    weath.loc[:,'DAY_OF_MONTH'] = weath['DAY_OF_MONTH'].astype(int)\n",
    "    weath.loc[:,'HOUR'] = [s for s in weath.datetime.str[11:13]]\n",
    "    weath.loc[:,'HOUR'] = weath['HOUR'].astype(int)\n",
    "    weath.drop(columns=['datetime'], inplace=True)\n",
    "    \n",
    "    # compress all not datetime data\n",
    "    for city in weather.columns:\n",
    "        if city == \"datetime\":\n",
    "            continue;\n",
    "                \n",
    "        # compress all not datetime data\n",
    "        if name != \"_WEATHER\":\n",
    "            weath.fillna(0, inplace=True)\n",
    "            weath.loc[:,city] = weath[city].astype(np.int16)\n",
    "    print(\"Refactored weather, \", name)\n",
    "            \n",
    "    line = line.merge(weath, on=['YEAR','MONTH','DAY_OF_MONTH','HOUR'])\n",
    "    print(\"Merged weather, \", name)\n",
    "        \n",
    "    #Rename the columns\n",
    "    for city in weather.columns:\n",
    "        if city == \"datetime\":\n",
    "            continue;             \n",
    "        \n",
    "        line.rename(columns={city: city + name}, inplace=True)\n",
    "    print(\"Completed column rename, \", name)\n",
    "        \n",
    "        \n",
    "    return line\n",
    "            \n",
    "    \n",
    "\n",
    "airline_df = join_weather_data(airline_df, humidity, \"_HUMIDITY\")\n",
    "print(\"Added HUMIDITY\")\n",
    "airline_df = join_weather_data(airline_df, pressure, \"_PRESSURE\")\n",
    "print(\"Added PRESSURE\")\n",
    "airline_df = join_weather_data(airline_df, temperature, \"_TEMPERATURE\")\n",
    "print(\"Added TEMPERATURE\")\n",
    "airline_df = join_weather_data(airline_df, wind_dir, \"_WIND_DIR\")\n",
    "print(\"Added WIND_DIR\")\n",
    "airline_df = join_weather_data(airline_df, wind_speed, \"_WIND_SPEED\")\n",
    "print(\"Added WIND_SPEED\")\n",
    "airline_df = join_weather_data(airline_df, weather_desc, \"_WEATHER\")\n",
    "print(\"Added WEATHER\")\n",
    " \n",
    "print(\"Memory after merges\")\n",
    "print(airline_df.memory_usage(deep=True).sum())\n",
    "\n",
    "# This DF is too large to process(kernal hangs on not enough disk space), need to break it into parts\n",
    "file_subset_size = 50000\n",
    "file_subset_index = 0\n",
    "file_subset_marker = 0\n",
    "airline_size = len(airline_df.index)\n",
    "cities = humidity.columns\n",
    "\n",
    "\n",
    "file_final_df = pd.DataFrame()\n",
    "while file_subset_marker < airline_size:\n",
    "    file_subset_df = pd.DataFrame()\n",
    "    if (file_subset_index + file_subset_size) < airline_size:\n",
    "        file_subset_df = airline_df.loc[file_subset_marker:file_subset_marker+file_subset_size-1]\n",
    "    else:\n",
    "        file_subset_df = airline_df.loc[file_subset_marker:airline_size]\n",
    "    \n",
    "        \n",
    "    subset_size = 5000\n",
    "    subset_marker = 0\n",
    "    file_size = len(file_subset_df.index)\n",
    "    \n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    while subset_marker < file_subset_size:\n",
    "        subset_df = pd.DataFrame()\n",
    "        middle_df = final_df\n",
    "        if (subset_marker + subset_size) < file_size:\n",
    "            subset_df = file_subset_df.loc[subset_marker:subset_marker+subset_size-1].copy()\n",
    "        else:\n",
    "            subset_df = file_subset_df.loc[subset_marker:file_size].copy()\n",
    "\n",
    "    \n",
    "        # Condense the weather data in the dataframe\n",
    "        weather = [\"_HUMIDITY\", \"_PRESSURE\", \"_TEMPERATURE\",\"_WIND_DIR\", \"_WIND_SPEED\", \"_WEATHER\"]\n",
    "                                \n",
    "        # Go through rows only once    \n",
    "        for index, row in subset_df.iterrows():\n",
    "            for name in weather:\n",
    "                # Continue by create one columns with origin/dest weather point\n",
    "                for city in cities:\n",
    "                    found_origin = False\n",
    "                    found_dest = False\n",
    "                    if row[\"ORIGIN_CITY_NAME\"] == city:\n",
    "                        subset_df.at[index, \"ORIGIN\" + name] = row[city + name]\n",
    "                        found_origin = True\n",
    "                        if found_dest:\n",
    "                            break\n",
    "                    if row[\"DEST_CITY_NAME\"] == city:\n",
    "                        subset_df.at[index, \"DEST\" + name] = row[city + name]\n",
    "                        found_dest = True\n",
    "                        if found_origin:\n",
    "                            break\n",
    "                    \n",
    "                        \n",
    "        # drop the city, we don't need it anymore\n",
    "        for name in weather:\n",
    "            for city in cities:\n",
    "                city_weath = city + name\n",
    "                if city_weath in subset_df.columns:\n",
    "                    subset_df.drop(columns=[city_weath], inplace=True)\n",
    "                    \n",
    "\n",
    "        print(\"Done with \", subset_marker + subset_size)\n",
    "            \n",
    "        subset_marker += subset_size\n",
    "        final_df = pd.concat([middle_df, subset_df])      \n",
    "\n",
    "        \n",
    "    file_final_df = final_df\n",
    "    \n",
    "\n",
    "    # Turn all floats to ints, we likely don't need percision\n",
    "    file_final_df.fillna(0, inplace=True)\n",
    "    file_final_df.loc[:,'DEST_HUMIDITY'] = file_final_df['DEST_HUMIDITY'].astype(np.int16)\n",
    "    file_final_df.loc[:,'ORIGIN_HUMIDITY'] = file_final_df['ORIGIN_HUMIDITY'].astype(np.int16)\n",
    "    file_final_df.loc[:,'DEST_PRESSURE'] = file_final_df['DEST_PRESSURE'].astype(np.int16)\n",
    "    file_final_df.loc[:,'ORIGIN_PRESSURE'] = file_final_df['ORIGIN_PRESSURE'].astype(np.int16)\n",
    "    file_final_df.loc[:,'DEST_TEMPERATURE'] = file_final_df['DEST_TEMPERATURE'].astype(np.int16)\n",
    "    file_final_df.loc[:,'ORIGIN_TEMPERATURE'] = file_final_df['ORIGIN_TEMPERATURE'].astype(np.int16)\n",
    "    file_final_df.loc[:,'DEST_WIND_DIR'] = file_final_df['DEST_WIND_DIR'].astype(np.int16)\n",
    "    file_final_df.loc[:,'ORIGIN_WIND_DIR'] = file_final_df['ORIGIN_WIND_DIR'].astype(np.int8)\n",
    "    file_final_df.loc[:,'DEST_WIND_SPEED'] = file_final_df['DEST_WIND_SPEED'].astype(np.int16)\n",
    "    file_final_df.loc[:,'ORIGIN_WIND_SPEED'] = file_final_df['ORIGIN_WIND_SPEED'].astype(np.int16)\n",
    "    \n",
    "    file_final_df.to_csv(\"../airline_data/airlines_and_weather\" + str(file_subset_index) + \".csv\",index=False)\n",
    "    \n",
    "    file_subset_index += 1\n",
    "    file_subset_marker += file_subset_size\n",
    "    \n",
    "\n",
    "    \n",
    "# reread output and concatinate\n",
    "airline_list = []\n",
    "for i in range(48):\n",
    "    airline_list.append(pd.read_csv(\"../airline_data/airlines_and_weather\" + str(i) + \".csv\"))\n",
    "    \n",
    "airline_df = pd.concat(airline_list)\n",
    "print(len(airline_df.index))\n",
    "\n",
    "\n",
    "print(\"Current memory usage\")\n",
    "print(airline_df.memory_usage(deep=True).sum())\n",
    "\n",
    "# do this refacot at the end to maintain the same code throughout\n",
    "descs = list(set(airline_df['DEST_WEATHER']).union(set(airline_df['ORIGIN_WEATHER'])))\n",
    "code = 0\n",
    "for condition in descs:\n",
    "    airline_df.replace(condition, code, inplace=True)\n",
    "    print(code, \",\", condition)\n",
    "    code += 1\n",
    "    \n",
    "airline_df.loc[:,'DEST_WEATHER'] = airline_df['DEST_WEATHER'].astype(np.int8)\n",
    "airline_df.loc[:,'ORIGIN_WEATHER'] = airline_df['ORIGIN_WEATHER'].astype(np.int8)\n",
    "\n",
    "    \n",
    "print(\"Final memory usage\")\n",
    "print(airline_df.memory_usage(deep=True).sum())  \n",
    "    \n",
    "airline_df.to_csv(\"../airline_data/airlines_and_weather.csv\",index=False)\n",
    "print(\"Output to csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jan_2015' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2f61b54a6998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Concatinate the rest of the data together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweather_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjan_2015\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mapr_2015\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mchicago\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweather_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ORIGIN_CITY_NAME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Chicago'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchicago\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchicago\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"YEAR\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"MONTH\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"DAY_OF_MONTH\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"CRS_DEP_TIME\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ORIGIN_CITY_NAME\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"CANCELLED\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"CANCELLATION_CODE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jan_2015' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
